{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import spacy\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import en_core_web_sm\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "from pprint import pprint\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm_note\n",
    "import tqdm\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the document list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the doc_list file\n",
    "#load the pickle \n",
    "filename= 'doc_spacyall'\n",
    "infile= open(filename,'rb')\n",
    "load_doc_spacyall = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the doc_list file\n",
    "#load the pickle \n",
    "filename= 'doc_nltk_bitri'\n",
    "infile= open(filename,'rb')\n",
    "load_doc_nltk_bitri = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the doc_list file\n",
    "#load the pickle \n",
    "filename= 'doc_clean_tweet'\n",
    "infile= open(filename,'rb')\n",
    "load_doc_clean_tweet = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cautions : This notebook takes a long time to Run. Thus I will not restart the kernel   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before buliding the LDA Model,I am trying to search for the best K topics by refering to coherence score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for LDA model, \n",
    "#pass the corpus with different pre-proccessing, number of topics, and number of iterition(passes)\n",
    "\n",
    "def lda_model_fuc (filename, k, n):\n",
    "    \n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=filename,\n",
    "                                               id2word=words,\n",
    "                                               num_topics=k, \n",
    "                                               random_state=2,\n",
    "                                               update_every=1,\n",
    "                                               passes=n,\n",
    "                                               alpha='auto',\n",
    "                                               per_word_topics=True)\n",
    "    pprint(lda_model.print_topics(num_words=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for conference score\n",
    "#help with determine the number of topics.\n",
    "\n",
    "def coherence (k,n,load_doc_name):\n",
    "    words = corpora.Dictionary(load_doc_name)\n",
    "    corpus = [words.doc2bow(doc) for doc in load_doc_name]\n",
    "    lda_model = LDA(corpus=corpus, id2word=words, num_topics=k, random_state=100,\n",
    "                chunksize=200, passes=n, per_word_topics=True)\n",
    "\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=load_doc_name, dictionary=words, coherence='c_v')\n",
    "    coherence_lda = round(coherence_model_lda.get_coherence(),4)\n",
    "    print(f'Coherence Score of {k} Topics: {(coherence_lda)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the coherence score of pre-processing `SpaCy pipelines` for 3-10 number of topics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### caution: the comparison of the coherence score take long time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb684df24c0e4e76a90e7c40c8e4fc8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 3 Topics: 0.3442\n",
      "Coherence Score of 4 Topics: 0.3519\n",
      "Coherence Score of 5 Topics: 0.3295\n",
      "Coherence Score of 6 Topics: 0.3491\n",
      "Coherence Score of 7 Topics: 0.3194\n",
      "Coherence Score of 8 Topics: 0.309\n",
      "Coherence Score of 9 Topics: 0.2965\n",
      "Coherence Score of 10 Topics: 0.315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#set the number of iterition(passes) to 20 \n",
    "for num_topic in tqdm_note(range(3,11)):\n",
    "    coherence (num_topic,20,load_doc_spacyall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdac880f93794f41b631f1fbaf7d75fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 3 Topics: 0.3455\n",
      "Coherence Score of 4 Topics: 0.3519\n",
      "Coherence Score of 5 Topics: 0.3295\n",
      "Coherence Score of 6 Topics: 0.3491\n",
      "Coherence Score of 7 Topics: 0.3176\n",
      "Coherence Score of 8 Topics: 0.3065\n",
      "Coherence Score of 9 Topics: 0.2965\n",
      "Coherence Score of 10 Topics: 0.3147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#set the number of iterition(passes) to 10 \n",
    "for num_topic in tqdm_note(range(3,11)):\n",
    "    coherence (num_topic,10,load_doc_spacyall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the coherence score of pre-processing `NLTK &Bigram/Trigram` for 3-10 number of topics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### caution: the comparison of the coherence score take long time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##set the number of iterition(passes) to 20\n",
    "\n",
    "#for num_topic in tqdm_note(range(3,11)):\n",
    " #   coherence (num_topic,20,load_doc_nltk_bitri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will only run for 10 passes as we can see that the score with passes 10 times and the score with passes 20 are almost the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd7ddcb694e4891bc1702c4dfd04dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 3 Topics: 0.3515\n",
      "Coherence Score of 4 Topics: 0.3405\n",
      "Coherence Score of 5 Topics: 0.3369\n",
      "Coherence Score of 6 Topics: 0.3549\n",
      "Coherence Score of 7 Topics: 0.3201\n",
      "Coherence Score of 8 Topics: 0.3251\n",
      "Coherence Score of 9 Topics: 0.3117\n",
      "Coherence Score of 10 Topics: 0.3254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#set the number of iterition(passes) to 10 \n",
    "\n",
    "for num_topic in tqdm_note(range(3,11)):\n",
    "    coherence (num_topic,10,load_doc_nltk_bitri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the coherence score of pre-processing `tweet cleaning` for 3-10 number of topics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### caution: the comparing of the coherence score take long time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 3 Topics: 0.3568536642512174\n",
      "Coherence Score of 4 Topics: 0.3133538450797512\n",
      "Coherence Score of 5 Topics: 0.32682706598055083\n",
      "Coherence Score of 6 Topics: 0.2956369565190991\n",
      "Coherence Score of 7 Topics: 0.3442207300846051\n",
      "Coherence Score of 8 Topics: 0.331717454078419\n",
      "Coherence Score of 9 Topics: 0.32139580483673746\n",
      "Coherence Score of 10 Topics: 0.3270063066711949\n"
     ]
    }
   ],
   "source": [
    "#set the number of iterition(passes) to 20 \n",
    "\n",
    "#for num_topic in tqdm_note(range(3,11)):\n",
    " #   coherence (num_topic,20,load_doc_clean_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will only run for 10 passes as we can see that the score with passes 10 times and the score with passes 20 are almost the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4baf4d7877489ba3358a29ad287607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 3 Topics: 0.3688\n",
      "Coherence Score of 4 Topics: 0.3353\n",
      "Coherence Score of 5 Topics: 0.336\n",
      "Coherence Score of 6 Topics: 0.3142\n",
      "Coherence Score of 7 Topics: 0.3207\n",
      "Coherence Score of 8 Topics: 0.304\n",
      "Coherence Score of 9 Topics: 0.3123\n",
      "Coherence Score of 10 Topics: 0.296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# #set the number of iterition(passes) to 10 \n",
    "\n",
    "for num_topic in tqdm_note(range(3,11)):\n",
    "    coherence (num_topic,10,load_doc_clean_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Short summary of the above coherence score__\n",
    "\n",
    "Overall the coherence score are low. The highest score is 0.3688 tweet cleaning with 3 topics\n",
    "The passess didn't affect the coherence score as we can see that the score with passes 10 times and the score with passes 20 are almost the same.\n",
    "\n",
    "It's possible to tune for the parameter k , **number of topics**, though it's not necessarily a very straightforward way to improve the model, I will try to tune the hyperparameter aiming at getting a higher coherence score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning hyperparameter : alpha and eta(beta) are hyperparameters that affect sparsity of the topics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tuning LDA model can be tough__\n",
    "\n",
    "More legitimate implementations of LDA have hyperparameters such as alpha. Alpha is a scaler that helps minimize an error term. Most LDA models that are implented will set this automatically and it's usually, 95% of the time a fine solution. \n",
    "\n",
    "As the coherence scores above are not ideal with auto alpha, I will perform a series of sensitivity tests to help determine the following model hyperparameters:\n",
    "- Number of Topics (K)\n",
    "- Dirichlet hyperparameter alpha: Document-Topic Density\n",
    "- Dirichlet hyperparameter beta: Word-Topic Density\n",
    "\n",
    "Alpha parameter is Dirichlet prior concentration parameter that represents document-topic density — with a higher alpha, documents are assumed to be made up of more topics and result in more specific topic distribution per document.\n",
    "\n",
    "Beta parameter is the same prior concentration parameter that represents topic-word density — with high beta, topics are assumed to made of up most of the words and result in a more specific word distribution per topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for tunning coherence score\n",
    "# Here i will set the passes = 20 because the coherence score are \n",
    "def coherence_tuning(corpus, load_doc_name, k, a, b):\n",
    "    words = corpora.Dictionary(load_doc_name)\n",
    "    corpus = [words.doc2bow(doc) for doc in load_doc_name]\n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=words,\n",
    "                                           num_topics=k, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=20,\n",
    "                                           alpha=a,\n",
    "                                           eta=b,\n",
    "                                           per_word_topics= True)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=load_doc_name, dictionary=words, coherence='c_v')\n",
    "    \n",
    "    #return coherence_model_lda.get_coherence()\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    print(f'Coherence Score of {k} Topics: {coherence_lda}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "\n",
    "# Topics range\n",
    "min_topics = 3\n",
    "max_topics = 6\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.1, 1, 0.3))\n",
    "alpha.append('symmetric')\n",
    "alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.1, 1, 0.3))\n",
    "beta.append('symmetric')\n",
    "\n",
    "# Validation sets\n",
    "num_of_docs = len(corpus)\n",
    "corpus_sets = [corpus]\n",
    "\n",
    "corpus_title = ['100% Corpus']\n",
    "\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cautions: the cell below take 14 hours to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/60 [12:40<12:27:51, 760.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 3 Topics: 0.31233030049287835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 2/60 [25:13<12:12:57, 758.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 3 Topics: 0.29071935193145293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 3/60 [37:58<12:02:22, 760.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 3 Topics: 0.3338800741499322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 4/60 [50:26<11:46:07, 756.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 3 Topics: 0.2959705337560576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 5/60 [1:03:52<11:47:14, 771.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 3 Topics: 0.33485752940179964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 6/60 [1:17:03<11:39:26, 777.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 3 Topics: 0.3600810768710076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▏        | 7/60 [1:29:40<11:21:17, 771.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 3 Topics: 0.3658920207079472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|█▎        | 8/60 [1:43:46<11:27:54, 793.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 3 Topics: 0.33998467679111344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 9/60 [2:01:30<12:23:31, 874.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 3 Topics: 0.37193037543286595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 10/60 [2:19:15<12:56:22, 931.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 3 Topics: 0.3620268528794126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|█▊        | 11/60 [2:32:43<12:10:32, 894.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 3 Topics: 0.3529998159326832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 12/60 [2:45:45<11:28:42, 860.88s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 3 Topics: 0.35952763638169943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 13/60 [2:58:26<10:50:50, 830.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 3 Topics: 0.3276435949527317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|██▎       | 14/60 [3:11:39<10:28:16, 819.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 3 Topics: 0.36023143576578304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 15/60 [3:25:36<10:18:44, 824.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 3 Topics: 0.38650308858002597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|██▋       | 16/60 [3:39:10<10:02:31, 821.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 3 Topics: 0.3026075470132749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|██▊       | 17/60 [3:51:08<9:26:28, 790.42s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 3 Topics: 0.35965685919413976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 18/60 [4:04:17<9:12:57, 789.95s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 3 Topics: 0.345564927516729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 32%|███▏      | 19/60 [4:17:06<8:55:31, 783.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 3 Topics: 0.41316498511403105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 20/60 [4:29:24<8:33:18, 769.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 3 Topics: 0.3770002893034549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 21/60 [4:42:42<8:26:02, 778.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 4 Topics: 0.40761141006306223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 37%|███▋      | 22/60 [4:56:08<8:18:16, 786.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 4 Topics: 0.3998717720580424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 38%|███▊      | 23/60 [5:10:22<8:17:39, 807.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 4 Topics: 0.4085525499955733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 24/60 [5:24:00<8:06:08, 810.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 4 Topics: 0.34748535615131515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|████▏     | 25/60 [5:36:49<7:45:24, 797.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 4 Topics: 0.3199072590731923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 43%|████▎     | 26/60 [5:50:35<7:36:55, 806.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 4 Topics: 0.35827971083910215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 27/60 [6:03:54<7:22:09, 803.92s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 4 Topics: 0.36715356267838417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47%|████▋     | 28/60 [6:18:00<7:15:37, 816.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 4 Topics: 0.3388160695074661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 48%|████▊     | 29/60 [6:32:10<7:07:01, 826.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 4 Topics: 0.37602138800015283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 30/60 [6:46:08<6:55:06, 830.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 4 Topics: 0.3351375183533646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 52%|█████▏    | 31/60 [6:59:44<6:39:08, 825.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 4 Topics: 0.35719213558467233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 53%|█████▎    | 32/60 [7:13:50<6:28:11, 831.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 4 Topics: 0.3468843763365209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 33/60 [7:27:12<6:10:18, 822.91s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 4 Topics: 0.31373025648235225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 57%|█████▋    | 34/60 [7:40:41<5:54:47, 818.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 4 Topics: 0.3595171749376418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 58%|█████▊    | 35/60 [7:54:32<5:42:42, 822.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 4 Topics: 0.4469748529454709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 36/60 [8:08:05<5:27:48, 819.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 4 Topics: 0.32080188278184363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 62%|██████▏   | 37/60 [8:21:05<5:09:40, 807.83s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 4 Topics: 0.3600177784485105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 63%|██████▎   | 38/60 [8:34:29<4:55:42, 806.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 4 Topics: 0.37165197179708725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 39/60 [8:48:10<4:43:48, 810.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 4 Topics: 0.3959035522135009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 40/60 [9:01:46<4:30:49, 812.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 4 Topics: 0.3274242626281167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 68%|██████▊   | 41/60 [9:16:12<4:22:21, 828.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 5 Topics: 0.3571042485045842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 42/60 [9:31:04<4:14:17, 847.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 5 Topics: 0.4360955816488737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 72%|███████▏  | 43/60 [9:45:44<4:02:52, 857.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 5 Topics: 0.41735114020465514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 73%|███████▎  | 44/60 [10:02:47<4:01:50, 906.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 5 Topics: 0.2952045817673471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 45/60 [10:16:58<3:42:34, 890.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 5 Topics: 0.3491293644766922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 77%|███████▋  | 46/60 [10:33:38<3:35:25, 923.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 5 Topics: 0.40891121939673536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 78%|███████▊  | 47/60 [10:49:11<3:20:37, 925.96s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 5 Topics: 0.42332313949064115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 48/60 [11:04:38<3:05:16, 926.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 5 Topics: 0.35650552112991607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 82%|████████▏ | 49/60 [11:18:45<2:45:27, 902.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 5 Topics: 0.35340402810138627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|████████▎ | 50/60 [11:33:04<2:28:14, 889.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 5 Topics: 0.40426221696806036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 51/60 [11:47:26<2:12:12, 881.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 5 Topics: 0.34638352997757205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 87%|████████▋ | 52/60 [12:00:48<1:54:20, 857.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 5 Topics: 0.3671504545298053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 88%|████████▊ | 53/60 [12:14:57<1:39:44, 854.91s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 5 Topics: 0.31269540208018026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 54/60 [12:30:39<1:28:06, 881.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 5 Topics: 0.39189973235088493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 92%|█████████▏| 55/60 [12:45:41<1:13:56, 887.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 5 Topics: 0.39850885392992996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 93%|█████████▎| 56/60 [13:00:19<58:57, 884.50s/it]  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 5 Topics: 0.3392961892665832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 57/60 [13:14:19<43:32, 870.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 5 Topics: 0.37148273090921224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 97%|█████████▋| 58/60 [13:29:05<29:11, 875.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 5 Topics: 0.4325252149550566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 98%|█████████▊| 59/60 [13:43:47<14:37, 877.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 5 Topics: 0.4308405576536586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 60/60 [13:58:22<00:00, 838.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 5 Topics: 0.3283152261973334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Can take a long time to run\n",
    "#I run this cell only once and will not run it again as it takes a very long time\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=(len(beta)*len(alpha)*len(topics_range)*len(corpus_title)))\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    cv = coherence_tuning(corpus,load_doc_spacyall, \n",
    "                                                  k=k, a=a, b=b)\n",
    "                    # Save the model results\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results['Topics'].append(k)\n",
    "                    model_results['Alpha'].append(a)\n",
    "                    model_results['Beta'].append(b)\n",
    "                    model_results['Coherence'].append(cv)\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "    pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the saved csv as dataframe\n",
    "lda_tunning = pd.read_csv('lda_tuning_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Validation_Set           100% Corpus\n",
       "Topics                             4\n",
       "Alpha                      symmetric\n",
       "Beta              0.7000000000000001\n",
       "Coherence                        NaN\n",
       "Name: 34, dtype: object"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding the best hyperparameters\n",
    "lda_tunning.iloc[34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score of 4 Topics: 0.4400192893615461\n"
     ]
    }
   ],
   "source": [
    "#checking the best with the best hyperparaters\n",
    "best_score = coherence_tuning(corpus,load_doc_spacyall,k=4, a='symmetric', b=0.7000000000000001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Summary:__\n",
    "From the tuning process , I make a mistake that I set the output of `function of coherence tunning `( as ` print(f'Coherence Score of {k} Topics: {coherence_lda}'` , this is a string and that is why the value of coherence score on cvs file named `lda_tuning_results` become NaN. \n",
    "However, I am not going to rerun the cell as it takes too long time to run.\n",
    "\n",
    "I can find the hyperparameters (number of topic is 4, alpha is symmetric, beta is 0.7000000000000001) of best score by looking at the output below, the best score after tunning is around 0.45.\n",
    "It is on the index 35 of the dataframe lda_tunning.\n",
    "\n",
    "Coherence Score of 4 Topics: 0.4469748529454709\n",
    " 58%|█████▊    | 35/60 [7:54:32<5:42:42, 822.50s/it]\n",
    " \n",
    "\n",
    "This time I only run for one input `load_doc_spacyall` due to the long running time. Originally I plan to tune the other 2 inputs `load_doc_nltk_bitri` and `load_doc_clean_tweet` as well.\n",
    "\n",
    "Since the running time takes long time, I will first set 4 topics, alpha is auto and beta is none for each input. I will determine which input to use with the best hyperparameter. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
